# Set fluentd log level to error
<system>
  log_level "#{ENV['FLUENTD_LOG_LEVEL']}"
</system>

# Accept HTTP input
<source>
  @type http
  port 9880
  bind 0.0.0.0
  body_size_limit 32m
  keepalive_timeout 10s
</source>

# Accept events on tcp socket
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# Buffer and output to BQ
<match "#{ENV['FLUENTD_TAG']}">
  @type bigquery_load

  <buffer>
    @type file

    path "#{ENV['FLUENTD_LOG_PATH']}"
    timekey_use_utc
    
    flush_at_shutdown true
    flush_mode interval
    flush_interval "#{ENV['FLUENTD_FLUSH_INTERVAL_SECONDS']}"
    retry_max_times 3

    chunk_limit_size 1g
    compress gzip
    total_limit_size "#{ENV['FLUENTD_BUFFER_LIMIT']}"

    delayed_commit_timeout 150
    disable_chunk_backup true
  </buffer>

  # Authenticate with BigQuery using a json key
  auth_method json_key
  json_key "#{ENV['FLUENTD_GCP_JSON_KEY_PATH']}"
  project "#{ENV['FLUENTD_GCP_PROJECT']}"
  dataset "#{ENV['FLUENTD_BQ_DATASET']}"
  table "#{ENV['FLUENTD_BQ_TABLE']}"
  fetch_schema true
</match>